{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assignment 1**: Computing the area of the Mandelbrot Set\n",
    "\n",
    "Karolina Chlopicka, 15716546 <br>\n",
    "Shania Sinha, 14379031 <br>\n",
    "Salomé Poulain, 13955993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Callable\n",
    "from scipy.stats import qmc  # For Latin Hypercube sampling\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Mandelbrot Set\n",
    "\n",
    "Creating and visualizing an example of the Mandelbrot set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDING_BOX_X = (-2.5, 1.5)\n",
    "BOUNDING_BOX_Y = (-2, 2)\n",
    "BOUND = 2\n",
    "RESOLUTION_POINTS = 500\n",
    "POWER = 2\n",
    "MAX_ITER = 100 # Maximum number of iterations to check for convergence\n",
    "SEED = 42\n",
    "\n",
    "LITERARY_VALUE = 1.506591856 ####### idk\n",
    "\n",
    "# COLOURS ??? maybe nice for the future "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mandelbrot(\n",
    "    X: np.ndarray, \n",
    "    Y: np.ndarray, \n",
    "    bound: float = BOUND,\n",
    "    power: int = POWER, \n",
    "    max_iter: int = MAX_ITER\n",
    ") -> List[List[int]]:\n",
    "    \"\"\"\n",
    "    Compute the Mandelbrot set for given x and y ranges.\n",
    "\n",
    "    Parameters:\n",
    "        X (np.ndarray): Array of x values (real parts of complex plane).\n",
    "        Y (np.ndarray): Array of y values (imaginary parts of complex plane).\n",
    "        bound (float): Threshold for divergence in the Mandelbrot set.\n",
    "        power (int): The exponent for complex power in Mandelbrot iteration.\n",
    "        max_iter (int): Maximum number of iterations to compute per point.\n",
    "\n",
    "    Returns:\n",
    "        List[List[int]]: 2D list where each element represents the iteration count \n",
    "                         before divergence, or 0 if the point belongs to the set.\n",
    "    \"\"\"\n",
    "    mandelbrot_set = []\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    C = X + 1j * Y  # Create a grid of complex numbers\n",
    "    Z = np.zeros_like(C, dtype=complex)\n",
    "    div_iter = np.zeros(C.shape, dtype=int)  # Track divergence iteration counts\n",
    "\n",
    "    # Iteratively compute the Mandelbrot set\n",
    "    for i in range(1, max_iter + 1):\n",
    "        mask = np.abs(Z) < bound\n",
    "        Z[mask] = Z[mask] ** power + C[mask]  # Update only non-diverging points\n",
    "        div_iter[mask & (np.abs(Z) >= bound)] = i  # Record when they diverge\n",
    "\n",
    "    mandelbrot_set = div_iter.tolist()  # Convert to a list of lists\n",
    "    return mandelbrot_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters\n",
    "all_x = np.linspace(BOUNDING_BOX_X[0], BOUNDING_BOX_X[1], RESOLUTION_POINTS)\n",
    "all_y = np.linspace(BOUNDING_BOX_Y[0], BOUNDING_BOX_Y[1], RESOLUTION_POINTS)\n",
    "\n",
    "colormap = 'magma'\n",
    "\n",
    "mandelbrot_set = build_mandelbrot(all_x, all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "ax = plt.axes()\n",
    "ax.set_aspect('equal')\n",
    "graph = ax.pcolormesh(all_x, all_y, mandelbrot_set, cmap = colormap, shading='auto')\n",
    "plt.colorbar(graph)\n",
    "plt.xlabel(\"Real-Axis\")\n",
    "plt.ylabel(\"Imaginary-Axis\")\n",
    "plt.title(f\"Mandelbrot set for $z_{{new}} = z^{{power}} + c$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Investigate the convergence of $A_{i,s} \\rightarrow A_M$\n",
    "\n",
    "Investigating the area of the Mandelbrot set $A_M$ using Monte Carlo integration. $A_{i,s}$ denotes an estimate of an area, where $i$ refers to a number of iterations and $s$ refers to number of samples drawn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_points_mandelbrot(\n",
    "    X: np.ndarray, Y: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Check if points in a grid are within the Mandelbrot set.\n",
    "\n",
    "    Parameters:\n",
    "        X (np.ndarray): Array of x-coordinates (real parts of complex numbers).\n",
    "        Y (np.ndarray): Array of y-coordinates (imaginary parts of complex numbers).\n",
    "        bound (float): Threshold for divergence in the Mandelbrot set (default is 2.0).\n",
    "        max_iter (int): Maximum number of iterations for checking divergence (default is 100).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Boolean array of the same shape as X and Y, where True indicates\n",
    "                    that the point is in the Mandelbrot set (does not diverge within the\n",
    "                    iteration limit), and False indicates divergence.\n",
    "    \"\"\"\n",
    "    # Create the complex plane grid from X and Y values\n",
    "    C = X + 1j * Y\n",
    "    Z = np.zeros_like(C, dtype=complex)  \n",
    "    mask = np.ones(C.shape, dtype=bool)  \n",
    "\n",
    "    # Iteratively compute the Mandelbrot set\n",
    "    for _ in range(MAX_ITER):\n",
    "        Z[mask] = Z[mask] ** POWER + C[mask] \n",
    "        mask &= np.abs(Z) < BOUND            \n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_random(i: int, sample_size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Monte Carlo simulation to estimate the area of the Mandelbrot set.\n",
    "\n",
    "    Parameters:\n",
    "        i (int): Number of iterations.\n",
    "        sample_size (int): Number of samples per iteration.\n",
    "        bound (float): Threshold for divergence in the Mandelbrot set (default is 2.0).\n",
    "        max_iter (int): Maximum number of iterations for checking divergence.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array of estimated area of the Mandelbrot set for each iteration.\n",
    "    \"\"\"\n",
    "    area = (BOUNDING_BOX_X[1] - BOUNDING_BOX_X[0]) * (BOUNDING_BOX_Y[1] - BOUNDING_BOX_Y[0])\n",
    "    iterations = i\n",
    "    size_iterations = np.zeros(iterations)\n",
    "\n",
    "    for j in range(iterations):\n",
    "        # Generate random points within the bounding rectangle\n",
    "        x_coordinates = np.random.uniform(BOUNDING_BOX_X[0], BOUNDING_BOX_X[1], sample_size)\n",
    "        y_coordinates = np.random.uniform(BOUNDING_BOX_Y[0], BOUNDING_BOX_Y[1], sample_size)\n",
    "\n",
    "        # Check if the points are in the Mandelbrot set using the vectorized function\n",
    "        mask = _check_points_mandelbrot(x_coordinates, y_coordinates)\n",
    "\n",
    "        # Calculate the area estimation for this iteration\n",
    "        points_in_set = np.count_nonzero(mask)  \n",
    "        area_estimate = (points_in_set / sample_size) * area  \n",
    "\n",
    "        # Store the result of this iteration\n",
    "        size_iterations[j] = area_estimate\n",
    "    \n",
    "    return size_iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_iteration_statistics(size_iterations: np.ndarray) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of the given size iterations array.\n",
    "\n",
    "    Parameters:\n",
    "        size_iterations (np.ndarray): Array of area estimates from each Monte Carlo iteration.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float]: A tuple containing the mean and standard deviation.\n",
    "    \"\"\"\n",
    "    mean = np.mean(size_iterations)\n",
    "    std_dev = np.std(size_iterations)\n",
    "    return mean, std_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Testing the function\n",
    "monte_carlo_random(10000,1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1: Convergence of $A_{i,s} \\rightarrow A_M$ \n",
    "\n",
    "We set the sample size to $s=1000$, and investigate the convergence of the area when changing the number of iterations for all $j<i$ such that $i = 3000$ and $j = \\{100k: k \\in \\{1, 2, ..., 30\\}\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_trajectory_iterations(\n",
    "    sample_size: int, \n",
    "    start_iter: int, \n",
    "    end_iter: int, \n",
    "    measurements_amount: int,\n",
    "    monte_carlo_method: Callable[[int, int], np.ndarray],\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform a Monte Carlo convergence test to estimate the Mandelbrot set area and\n",
    "    standard deviation over varying numbers of iterations.\n",
    "\n",
    "    Parameters:\n",
    "        sample_size (int): Number of samples per iteration.\n",
    "        start_iter (int): Starting number of iterations.\n",
    "        end_iter (int): Ending number of iterations.\n",
    "        measurements_amount (int): Total number of different iteration counts to test.\n",
    "        monte_carlo_method (Callable): Monte Carlo method function to use for estimation.\n",
    "            The function should accept two arguments (iterations, sample_size) and return\n",
    "            an array of area estimates.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: A tuple containing:\n",
    "            - estimation_per_iteration (np.ndarray): Array of estimated areas per iteration count.\n",
    "            - std_dev_per_iteration (np.ndarray): Array of standard deviations per iteration count.\n",
    "    \"\"\"\n",
    "    # Generate an array of iteration counts between start_iter and end_iter\n",
    "    number_of_iterations = np.linspace(start_iter, end_iter, measurements_amount, dtype=int)\n",
    "    estimation_per_iteration = np.zeros(len(number_of_iterations))  # Store estimated area\n",
    "    std_dev_per_iteration = np.zeros(len(number_of_iterations))     # Store standard deviation\n",
    "\n",
    "    # Define a function for parallelized computation of area estimates per iteration\n",
    "    def compute_estimate(iterations):\n",
    "        area_estimates = monte_carlo_method(iterations, sample_size)\n",
    "        estimation, std_dev = _calculate_iteration_statistics(area_estimates)\n",
    "        return estimation, std_dev\n",
    "\n",
    "    # Parallelize across iteration counts\n",
    "    results = Parallel(n_jobs=measurements_amount)(\n",
    "        delayed(compute_estimate)(iterations) for iterations in number_of_iterations\n",
    "    )\n",
    "\n",
    "    # Store results into respective arrays\n",
    "    for i, (estimation, std_dev) in enumerate(results):\n",
    "        estimation_per_iteration[i] = estimation\n",
    "        std_dev_per_iteration[i] = std_dev\n",
    "\n",
    "    return estimation_per_iteration, std_dev_per_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_trajectory_samples(\n",
    "    iteration: int, \n",
    "    start_sample: int, \n",
    "    end_sample: int, \n",
    "    measurements_amount: int,\n",
    "    monte_carlo_method: Callable[[int, int], np.ndarray],\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Perform a Monte Carlo convergence test to estimate the Mandelbrot set area and\n",
    "    standard deviation over varying numbers of iterations.\n",
    "\n",
    "    Parameters:\n",
    "        sample_size (int): Number of samples per iteration.\n",
    "        start_iter (int): Starting number of iterations.\n",
    "        end_iter (int): Ending number of iterations.\n",
    "        measurements_amount (int): Total number of different iteration counts to test.\n",
    "        monte_carlo_method (Callable): Monte Carlo method function to use for estimation.\n",
    "            The function should accept two arguments (iterations, sample_size) and return\n",
    "            an array of area estimates.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: A tuple containing:\n",
    "            - estimation_per_iteration (np.ndarray): Array of estimated areas per iteration count.\n",
    "            - std_dev_per_iteration (np.ndarray): Array of standard deviations per iteration count.\n",
    "    \"\"\"\n",
    "    # Generate an array of iteration counts between start_iter and end_iter\n",
    "    number_of_samples = np.linspace(start_sample, end_sample, measurements_amount, dtype=int)\n",
    "    estimation_per_sample = np.zeros(len(number_of_samples))  # Store estimated area\n",
    "    std_dev_per_iteration = np.zeros(len(number_of_samples))     # Store standard deviation\n",
    "\n",
    "    # Define a function for parallelized computation of area estimates per iteration\n",
    "    def compute_estimate(sample):\n",
    "        area_estimates = monte_carlo_method(iteration, sample)\n",
    "        estimation, std_dev = _calculate_iteration_statistics(area_estimates)\n",
    "        return estimation, std_dev\n",
    "\n",
    "    # Parallelize across iteration counts\n",
    "    results = Parallel(n_jobs=measurements_amount)(\n",
    "        delayed(compute_estimate)(sample) for sample in number_of_samples\n",
    "    )\n",
    "\n",
    "    # Store results into respective arrays\n",
    "    for i, (estimation, std_dev) in enumerate(results):\n",
    "        estimation_per_sample[i] = estimation\n",
    "        std_dev_per_iteration[i] = std_dev\n",
    "\n",
    "    return std_dev_per_iteration, std_dev_per_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monte_carlo_methods(\n",
    "    method_names: List[str], \n",
    "    method_results: List[Tuple[np.ndarray, np.ndarray]],\n",
    "    start_iter: int,\n",
    "    end_iter: int,\n",
    "    measurements_amount: int,\n",
    "    expected_value: float,\n",
    "    plot_std: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot Monte Carlo convergence for different methods, showing both the estimated area, \n",
    "    the standard deviation around it (optional), and the difference in estimated area for each method.\n",
    "\n",
    "    Parameters:\n",
    "        method_names (List[str]): List of method names for labeling the plot.\n",
    "        method_results (List[Tuple[np.ndarray, np.ndarray]]): List of tuples containing \n",
    "            the estimation and standard deviation arrays for each method.\n",
    "        start_iter (int): Starting number of iterations.\n",
    "        end_iter (int): Ending number of iterations.\n",
    "        measurements_amount (int): Total number of different iteration counts to test.\n",
    "        expected_value (float): The \"literary\" or expected value to compare against.\n",
    "        plot_std (bool): Whether to plot standard deviation as a shaded region (default is False).\n",
    "\n",
    "    Returns:\n",
    "        None: This function plots the results directly.\n",
    "    \"\"\"\n",
    "    # Generate an array of iteration counts between start_iter and end_iter\n",
    "    number_of_iterations = np.linspace(start_iter, end_iter, measurements_amount, dtype=int)\n",
    "\n",
    "    # Set up the figure and subplots\n",
    "    figure, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "    # Loop over each method result and plot\n",
    "    for method_name, (estimation, std_dev) in zip(method_names, method_results):\n",
    "        # Plot the estimated area on the first subplot\n",
    "        ax1.plot(number_of_iterations, estimation, label=method_name)\n",
    "        \n",
    "        # Optionally plot the standard deviation as a shaded region around the estimated area\n",
    "        if plot_std:\n",
    "            ax1.fill_between(\n",
    "                number_of_iterations,\n",
    "                estimation - std_dev,\n",
    "                estimation + std_dev,\n",
    "                alpha=0.2,\n",
    "                label=f\"{method_name} ± 1 Std Dev\"\n",
    "            )\n",
    "        \n",
    "        # Calculate the difference from the final estimated area (convergence reference)\n",
    "        final_estimation = estimation[-1]  # Use the last estimation as the reference\n",
    "        difference = np.abs(estimation[:-1] - final_estimation)  # Difference with the reference\n",
    "        \n",
    "        # Plot the difference in estimated area on the second subplot\n",
    "        ax2.plot(number_of_iterations[:-1], difference, label=method_name)\n",
    "\n",
    "    # Configure the first subplot (Estimated Area)\n",
    "    ax1.set_xlabel(\"Number of Iterations\")\n",
    "    ax1.set_ylabel(\"Estimated Area of Mandelbrot Set\")\n",
    "    ax1.set_title(\"Estimated Area of Mandelbrot Set with Standard Deviation\" if plot_std else \"Estimated Area of Mandelbrot Set\")\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot the expected (literary) value as a horizontal line\n",
    "    ax1.axhline(y=expected_value, color='r', linestyle='--', label=f'Literary Value = {expected_value}')\n",
    "    ax1.legend(title=\"Methods\")\n",
    "\n",
    "    # Configure the second subplot (Difference in Estimated Area)\n",
    "    ax2.set_xlabel(\"Number of Iterations\")\n",
    "    ax2.set_ylabel(\"Difference relative to final estimated area\")\n",
    "    ax2.set_title(\"Difference in Estimated Area Convergence\")\n",
    "    ax2.grid(True)\n",
    "    ax2.legend(title=\"Methods\")\n",
    "\n",
    "    # Display the plots with tight layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monte_carlo_convergence_difference(\n",
    "    method_names: List[str], \n",
    "    method_results: List[Tuple[np.ndarray, np.ndarray]],\n",
    "    start_iter: int,\n",
    "    end_iter: int,\n",
    "    total_iterations: int,\n",
    "    expected_value: float,\n",
    "    plot_std: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot Monte Carlo convergence difference relative to the expected (literary) value for each iteration,\n",
    "    with standard deviation shown as a shaded region if desired.\n",
    "\n",
    "    Parameters:\n",
    "        method_names (List[str]): List of method names for labeling the plot.\n",
    "        method_results (List[Tuple[np.ndarray, np.ndarray]]): List of tuples containing \n",
    "            the estimation and standard deviation arrays for each method.\n",
    "        start_iter (int): Starting number of iterations.\n",
    "        end_iter (int): Ending number of iterations.\n",
    "        total_iterations (int): Total number of different iteration counts to test.\n",
    "        expected_value (float): The \"literary\" or expected value to compare against.\n",
    "        plot_std (bool): Whether to plot standard deviation as a shaded region (default is False).\n",
    "        \n",
    "    Returns:\n",
    "        None: This function plots the results directly.\n",
    "    \"\"\"\n",
    "    # Generate an array of iteration counts between start_iter and end_iter\n",
    "    number_of_iterations = np.linspace(start_iter, end_iter, total_iterations, dtype=int)\n",
    "\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Loop over each method result and plot\n",
    "    for method_name, (estimation, std_dev) in zip(method_names, method_results):\n",
    "        # Calculate the difference from the expected (literary) value\n",
    "        difference = np.abs(estimation - expected_value)\n",
    "\n",
    "        # Plot the convergence difference relative to the expected (literary) value\n",
    "        plt.plot(number_of_iterations, difference, label=method_name)\n",
    "        \n",
    "        # Optionally plot the standard deviation as a shaded region around the difference\n",
    "        if plot_std:\n",
    "            plt.fill_between(\n",
    "                number_of_iterations,\n",
    "                difference - std_dev,\n",
    "                difference + std_dev,\n",
    "                alpha=0.2,\n",
    "                label=f\"{method_name} ± 1 Std Dev\"\n",
    "            )\n",
    "\n",
    "    # Configure the plot\n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.ylabel(\"Difference from Expected Value\")\n",
    "    plt.title(\"Convergence Difference Relative to Expected Value\" + (\" with Standard Deviation\" if plot_std else \"\"))\n",
    "    plt.legend(title=\"Methods\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_monte_carlo_trajectory_samples(\n",
    "    method_names: List[str], \n",
    "    method_results: List[Tuple[np.ndarray, np.ndarray]],\n",
    "    start_sample: int,\n",
    "    end_sample: int,\n",
    "    measurements_amount: int,\n",
    "    expected_value: float,\n",
    "    plot_std: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Plot Monte Carlo convergence difference relative to the expected (literary) value for each iteration,\n",
    "    with standard deviation shown as a shaded region if desired.\n",
    "\n",
    "    Parameters:\n",
    "        method_names (List[str]): List of method names for labeling the plot.\n",
    "        method_results (List[Tuple[np.ndarray, np.ndarray]]): List of tuples containing \n",
    "            the estimation and standard deviation arrays for each method.\n",
    "        start_iter (int): Starting number of iterations.\n",
    "        end_iter (int): Ending number of iterations.\n",
    "        measurements_amount (int): Total number of different iteration counts to test.\n",
    "        expected_value (float): The \"literary\" or expected value to compare against.\n",
    "        plot_std (bool): Whether to plot standard deviation as a shaded region (default is False).\n",
    "        \n",
    "    Returns:\n",
    "        None: This function plots the results directly.\n",
    "    \"\"\"\n",
    "    # Generate an array of iteration counts between start_iter and end_iter\n",
    "    number_of_samples = np.linspace(start_sample, end_sample, measurements_amount, dtype=int)\n",
    "\n",
    "    # Set up the figure\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Loop over each method result and plot\n",
    "    for method_name, (estimation, std_dev) in zip(method_names, method_results):\n",
    "        # Calculate the difference from the expected (literary) value\n",
    "        difference = np.abs(estimation - expected_value)\n",
    "\n",
    "        # Plot the convergence difference relative to the expected (literary) value\n",
    "        plt.plot(number_of_samples, difference, label=method_name)\n",
    "        \n",
    "        # Optionally plot the standard deviation as a shaded region around the difference\n",
    "        if plot_std:\n",
    "            plt.fill_between(\n",
    "                number_of_samples,\n",
    "                difference - std_dev,\n",
    "                difference + std_dev,\n",
    "                alpha=0.2,\n",
    "                label=f\"{method_name} ± 1 Std Dev\"\n",
    "            )\n",
    "\n",
    "    # Configure the plot\n",
    "    plt.xlabel(\"Number of Iterations\")\n",
    "    plt.ylabel(\"Difference from Expected Value\")\n",
    "    plt.title(\"Convergence Difference Relative to Expected Value\" + (\" with Standard Deviation\" if plot_std else \"\"))\n",
    "    plt.legend(title=\"Methods\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "sample_size = 1000\n",
    "start_iter = 100\n",
    "end_iter = 1000000\n",
    "measurements_amount = 10\n",
    "\n",
    "# Define method names and results\n",
    "methods = [monte_carlo_random]  # Replace with actual functions\n",
    "method_names = ['Random Sampling']\n",
    "\n",
    "# Calculate results for each method\n",
    "results = [monte_carlo_trajectory_iterations(sample_size, start_iter, end_iter, measurements_amount, method) for method in methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plot_monte_carlo_methods(method_names, results, start_iter, end_iter, measurements_amount, expected_value=LITERARY_VALUE, plot_std=False)\n",
    "\n",
    "# plot_monte_carlo_convergence_difference(method_names, results, start_iter, end_iter, measurements_amount, expected_value=LITERARY_VALUE, plot_std=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Different Sampling Methods\n",
    "\n",
    "Explore different sampling methods. Namely:\n",
    "1. Pure random sampling\n",
    "2. Latin Hypercube sampling\n",
    "3. Orthogonal sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1: Pure Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2: Latin Hypercube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3: Orthogonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import qmc\n",
    "\n",
    "def oa_lhs(p, d, seed=None):\n",
    "    \"\"\"Generates an orthogonal array Latin hypercube sample.\n",
    "\n",
    "    Author: Pamphile Tupui ROY\n",
    "    Source: https://gist.github.com/tupui/3b79ecea1631e8925f3d47069d435b0f\n",
    "\n",
    "    Inputs:\n",
    "        p: number of levels\n",
    "        d: number of dimensions\n",
    "        seed: random seed\n",
    "\n",
    "    Output: orthogonal array Latin hypercube sample\n",
    "    \"\"\"\n",
    "    oa_sample = np.zeros(shape=(p**2, p + 1))\n",
    "\n",
    "    arrays = np.tile(np.arange(p), (2, 1))\n",
    "    oa_sample[:, :2] = np.stack(np.meshgrid(*arrays), axis=-1).reshape(-1, 2)\n",
    "    for p_ in range(1, p):\n",
    "        oa_sample[:, 2 + p_ - 1] = np.mod(oa_sample[:, 0] + p_ * oa_sample[:, 1], p)\n",
    "\n",
    "    # scramble the OA\n",
    "    oa_sample_ = np.empty(shape=(p**2, p + 1))\n",
    "    for j in range(p + 1):\n",
    "        perms = np.random.permutation(p)\n",
    "        for k in range(p):\n",
    "            idx = np.where(oa_sample[:, j] == k)[0]\n",
    "            oa_sample_[idx, j] = perms[k]\n",
    "    \n",
    "    oa_sample = oa_sample_\n",
    "\n",
    "    # Convert to OA-LHS\n",
    "    oa_lhs_sample = np.zeros(shape=(p**2, p + 1))\n",
    "    for j in range(p + 1):\n",
    "        for k in range(p):\n",
    "            idx = np.where(oa_sample[:, j] == k)[0]\n",
    "            lhs = qmc.LatinHypercube(d=1, centered=True, seed=seed).random(p).flatten()\n",
    "            oa_lhs_sample[:, j][idx] = lhs + oa_sample[:, j][idx]\n",
    "\n",
    "    oa_lhs_sample /= p\n",
    "\n",
    "    if d is not None:\n",
    "        oa_lhs_sample = oa_lhs_sample[:, :d]\n",
    "    return oa_lhs_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_oa_lhs(iterations, sample_size, x_min=-2, x_max=1.5, y_min=-2, y_max=2, seed=None):\n",
    "    # Calculate p to ensure p^2 >= sample_size\n",
    "    p = int(np.ceil(np.sqrt(sample_size)))\n",
    "    size_iterations = np.zeros(iterations)\n",
    "\n",
    "    for j in range(iterations):\n",
    "        point_in = np.zeros(sample_size)    # Storing points inside the Mandelbrot set\n",
    "        \n",
    "        # Generate OA-LHS samples for the bounding rectangle\n",
    "        oa_lhs_samples = oa_lhs(p, 2, seed=seed)\n",
    "        \n",
    "        # Scale the OA-LHS samples to the desired region\n",
    "        oa_lhs_samples[:, 0] = oa_lhs_samples[:, 0] * (x_max - x_min) + x_min\n",
    "        oa_lhs_samples[:, 1] = oa_lhs_samples[:, 1] * (y_max - y_min) + y_min\n",
    "\n",
    "        # Limit the samples to sample_size\n",
    "        oa_lhs_samples = oa_lhs_samples[:sample_size]\n",
    "        \n",
    "        for i in range(sample_size):\n",
    "            x_cordinate, y_cordinate = oa_lhs_samples[i]\n",
    "            if check_mandelbrot(x_cordinate, y_cordinate) == 1:\n",
    "                point_in[i] = 1\n",
    "        \n",
    "        # Calculate the estimated area for this iteration\n",
    "        size = (np.count_nonzero(point_in == 1) / sample_size) * ((x_max - x_min) * (y_max - y_min))\n",
    "        size_iterations[j] = size   \n",
    "    \n",
    "    # Calculate the average estimated area across all iterations\n",
    "    average_size = np.mean(size_iterations)\n",
    "    \n",
    "    return average_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "average_size = monte_carlo_oa_lhs(iterations=100, sample_size=10000, seed=42)\n",
    "print(f\"Estimated area of the Mandelbrot set: {average_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Improvements to Monte Carlo Convergence Rate\n",
    "\n",
    "Formulate and test a method to further improve the convergence rate of the Monte\n",
    "Carlo approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
